# 散列表和链表的组合使用

> 学习曲线：★★★

## LRU 缓存淘汰算法

* 在之前的章节里，我们了解过使用链表实现 LRU 缓存淘汰算法。下面先来概括地回顾。

### 链表实现 LRU

* 维护一个按照访问时间从大到小的的有序排列的链表结构。因为缓存大小有限，当缓存空间不够，需要淘汰一个数据的时候，就直接将链表头部的结点删除。
* 当需要缓存某个数据的时候，先在链表中查找这个数据，如果已经存在，就把该数据放到链表的尾部，否则，直接把数据放到链表的尾部。
	* 因为查找数据需要遍历链表，所以**单纯使用链表实现的 LRU 缓存淘汰算法的时间复杂度很高，是 `O(n)`.**

### 缓存(Cache)系统

* 一个合格的缓存系统通常包括以下几个操作：
	* 在缓存中添加一个数据；
	* 在缓存中删除一个数据；
	* 在缓存中查找一个数据。
* 实际上，这三个操作都会涉及查找的操作。如果使用链表，时间复杂度就是 `O(n)`.
* 而如果**使用散列表和链表这两种结构进行组合，可以把三个操作的时间复杂度都降低到 `O(1)`.**
	* 下面就是具体的结构：

![[散列表和链表实现缓存.png]]

* 这里使用了**双向链表**，而结点中除了数据(data)、前驱指针(prev) 和后继指针(next)外，还新增了一个特殊字段 hnext.
* 散列表是通过链表法解决散列冲突的，所以每个结点都是同时处于两条链中。
	* 一个是刚刚提到的双向链表；
	* 还有一个是散列表中的拉链。
* **前驱和后继指针是为了将结点串在双向链表中，hnext 指针是为了将结点串在散列表的拉链中。**

#### 缓存系统中的操作

* **查询数据操作**：散列表中，查找数据的时间复杂度是 `O(1)`. 所以在散列表和链表结合的缓存中查找，时间复杂度也是 `O(1)`。
	* 通过查询得到数据所在之后，再将该数据移动到双向链表的尾部。
* **删除数据操作**：核心是找到数据，再将其删除。
	* 借助散列表，可以在 `O(1)` 的复杂度内找到数据所在位置。
	* 再借助双向链表的前驱指针找到前驱结点，直接进行删除。因此双向链表中的删除结点也只需要 `O(1)` 的时间复杂度。
* **添加数据操作**：整个过程是先查询数据是否存在于当前缓存，如果有，就把数据移动到尾部；如果没有，就判断缓存有没有满，如果没有空间，则需要先删除头部结点再插入数据到尾部，如果没有满，就直接在尾部插入数据。
* 这几个过程中的查找操作都可以借助散列表实现 `O(1)` 的时间复杂度。而其他的操作例如删除头结点，链表尾部插入数据，都可以借助双向链表在 `O(1)` 的时间内完成。*所以这三个操作的时间复杂度都是 `O(1)`.*
* 通过散列表和双向链表的组合使用，这就实现了一个高效的、支持 LRU 缓存淘汰算法的缓存系统原型、

## Redis 有序集合

* 在之前跳表的章节中，有关有序集合的操作是简化过后的。实际上在有序集合中，每个成员对象都会有两个重要的属性 `key`（键值） 和 `score`（分值）
* 实际使用中，不仅会用 `score` 来查找数据，也会通过 `key` 来查找数据。
	* 举例：在用户积分排行榜中，可以通过用户的 ID 来查找积分信息，也可以通过积分区间来查找用户 ID 或者姓名信息。
	* 这里的包含 ID、姓名和积分的用户信息，就是成员对象，用户 ID 是 `key`，积分是 `score`。

### Redis 有序集合的操作

* 添加一个成员对象；
* 按照键值来删除一个成员对象；
* 按照键值来查找一个成员对象；
* 按照分值区间查找数据，比如查找积分在 [100，256] 之间的成员对象；
* 按照分值从小到大排序成员变量；

#### Redis 有序集合分析

* 如果按照分值将成员对象组织成跳表的结构，那么按照键值来删除或查询成员对象就会比较慢，而解决方法和 LRU 缓存淘汰算法的解决方法类似。按照键值构建一个散列表，按照 key 来删除，查找成员对象的时间复杂度就变成 `O(1)`. 再借助跳表结构，其他操作也会非常高效。
	* 而查找成员对象的排名或者根据排名区间查找成员对象这些操作，刚才的组合结构就无法高效实现了。这块会在后续进行解答。

## Java LinkedHashMap

* 查看以下代码，猜测输出顺序：

```java
HashMap<Integer, Integer> m = new LinkedHashMap<>();
m.put(3, 11);
m.put(1, 12);
m.put(5, 23);
m.put(2, 22);

for (Map.Entry e : m.entrySet()) {
  System.out.println(e.getKey());
}
```

* 上面的代码会按照数据的插入顺序来打印，也就是依次输出 `3，1，5，2`.
* 散列表的键是通过散列函数打乱后无规律存储的，这是如何做到记录顺序的呢。
* `LinkedHashMap` 也是通过散列表和链表这两者组合在一起实现的。
	* 它不仅支持按照插入顺序来遍历数据，也支持按照访问顺序来遍历数据。
	* 查看以下代码：

```java
// 10是初始大小，0.75是装载因子，true是表示按照访问时间排序
HashMap<Integer, Integer> m = new LinkedHashMap<>(10, 0.75f, true);
m.put(3, 11);
m.put(1, 12);
m.put(5, 23);
m.put(2, 22);

m.put(3, 26);
m.get(5);

for (Map.Entry e : m.entrySet()) {
  System.out.println(e.getKey());
}
```

* 这段代码的打印结果是 **`1，2，3，5`**.
	* 每次调用 `put` 函数，往 `LinkedHashMap` 中添加数据的时候，都会将数据添加到链表的尾部。因此在前四个操作之后，链表中的数据是以下这样：

![[LinkedHashMap数据示意1.png]]

* 在第 8 行代码中，再次将键值为 3 的数据放入到 `LinkedHashMap` 时，会先查找这个键值是否已经存在。然后，再将已经存在的 `(3,11)` 删除，并且将新的 `(3,26)` 结点放到链表的尾部。因此，这个时候链表中的数据就是下面这样：

![[LinkedHashMap数据示意2.png]]

* 当第 9 行代码访问到 key 为 5 的数据的时候，我们将被访问到的数据移动到链表的尾部。因此，代码执行之后，链表中的数据是下面这样：

![[LinkedHashMap数据示意3.png]]

* 至此，也就理解了为什么它的打印顺序是这样的。
* 而且，按照访问时间排序的 `LinkedHashMap` 本身其实就是一个支持 LRU 缓存淘汰策略的缓存系统。两者的实现原理也是一致的。
* `LinkedHashMap` 是通过双向链表和散列表这两中数据结构实现的。`LinkedHashMap` 中的 **"Linked"** 实际指的是**双向链表**，而不是使用链表法解决散列冲突。

## 小结

### 散列表为何常和链表一起使用

* 散列表这类数据结构支持高效的数据插入、删除和查找操作，但是散列表中的数据是通过散列函数打乱之后无规律存储的，无法按照某种顺序来快速遍历数据。
	* 如果强行希望按照顺序遍历散列表中的数据，那么需要将散列表中的数据拷贝到数组中，排序后再进行遍历。
* 散列表是动态数据结构，不停会有数据插入和删除，所以每次需要按顺序遍历散列表中的数据的时候，都要先排序，那效率就会比较低。而链表就是为了解决这类问题而和散列表一起使用的。
* 简要地说，**链表很好地弥补了散列表无法按顺序遍历的缺陷。** 因此两者非常适合一起使用。

## 扩展

* 在以上例子里，如果把双向链表改成单链表，是否还能正常工作，为什么？
	* *个人认为是可以工作的，但是时间复杂度会大大提升，导致每个操作都变得很低效。*
* 假设猎聘网有10万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这10万个猎头ID和积分信息，让它能够支持这样几个操作：
	* 根据猎头 ID 快速查找、删除和更新这个猎头的积分信息；
	* 查找积分在某个区间的猎头 ID 列表；
	* 查找按照积分从小到大排名在第 x 位到 y 位之间的猎头 ID 列表。

#ALG  #ADT 