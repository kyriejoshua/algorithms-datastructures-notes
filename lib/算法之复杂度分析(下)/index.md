# 复杂度分析之四种时间复杂度分析

## 简言

* 本节主要关注四种时间复杂度分析的知识点。

## 最好、最坏情况时间复杂度

* 下面这段代码的时间复杂度很容易确认，就是 `O(n)`。

```typescript
/**
 * 查找相等项的索引
 * @param arr 
 * @param n 
 * @param x 
 * @returns 
 */
function find(arr: any[], x: any): number {
  let pos = -1;
  for (let i = 0; i < arr.length; i++) {
    if (arr[i] === x) {
      pos = i;
    }
  }
  return pos;
}
```

* 但假如我们对代码进行一部分优化，则它的复杂度分析将变得稍稍复杂一些。

```typescript
/**
 * 查找相等项的索引
 * @param arr 
 * @param n 
 * @param x 
 * @returns 
 */
function find(arr: any[], x: any): number {
  let pos = -1;
  for (let i = 0; i < arr.length; i++) {
    if (arr[i] === x) {
      pos = i;
      break;
    }
  }
  return pos;
}
```

* 在找到相同项之后，循环就会停止，因此第一个找到和最后一位找到的结果可能会相差很多。
* 为了表示代码在不同情况下的不同时间复杂度，我们引入三个概念，**最好情况时间复杂度、最坏情况时间复杂度，平均情况时间复杂度。**

### 最好情况时间复杂度

* **最好情况时间复杂度：在最理想的情况下，执行这段代码的时间复杂度。**
	* 对应到上文的代码，就是在数组的第一个位置查找到元素的场景。

### 最坏情况时间复杂度

* **最坏情况时间复杂度：在最糟糕的情况下，执行这段代码的时间复杂度。**
	* 如果数组中没有我们所要查找的变量，那么就需要把数组内的所有元素都遍历一遍。最坏情况就对应着这类场景。

## 平均时间复杂度

* *上文提到的最好情况时间复杂度和最坏情况时间复杂度实际上都是极端情况下的代码复杂度，发生的概率其实并不大。*
* 为了更好地表示平均情况下的复杂度，我们引入另一个概念：**平均情况时间复杂度。**

### 平均时间复杂度的分析

* 查找一个变量 x 在数组中的位置，有 n + 1 中情况：在数据的 0 ~ n - 1 的位置和不在数组中。
* 我们把每种情况下，查找需要遍历的元素个数累加起来，再除以 n + 1，就可以得到需要遍历的元素个数的平均数。即下图：

![[平均时间复杂度错误推导过程示意.png]]

* 根据大 O 表示法，可以忽略系数，因此这个公式计算的结果推导出的时间复杂度就是 `O(n)`.
* 这个结论虽然正确，但是*推导过程是不正确的*。*因为上文中的 n + 1 种情况的概率不是均等的。*
* 根据概率论，x 出现在数组中和不在数组中的概率可以近似理解为对等，也就是都为 1/2. 而在数组中的每个位置的概率都是相等的，这个比较容易理解。
* 我们可以简单把结果是否在数组中的可能性都当成是 1/2, 在数组内的有 n 个数，乘以 1/2；不在数组内的则就是 1/2, 以这个为基础去计算就会得到下图：

![[平均时间复杂度.png]]

* 这个得到的 `(3n+1)/4` 其实就是概率论中的**加权平均值**，也叫作**期望值**。因此平均时间复杂度的全称实际上是**加权平均时间复杂度**或者**期望时间复杂度**。
* 在去除无关的系数之后，所得到的的平均时间复杂度也就是 `O(n)`。和上面的结果一样。
* **同一块代码，在不同的场景下，时间复杂度有量级的差距，才会使用以上三种复杂度表示法来区分。** 通常情况下不会全部都区分。

## 均摊时间复杂度

* 对应的分析方法叫**摊还分析（又叫平摊分析）**；它的应用场景比平均时间复杂度分析的场景更加特殊，更加有限。
* 下面是一个案例，实际中并不常见，这里只是为了分析:

```typescript
let arr = new Array(100); // 这里的 100 也可以是很大的数
let count = 0;
function insert(val: number): void {
  if (count === arr.length) {
    let sum = 0;
    for (let i = 0; i < arr.length; i++) {
      sum += arr[i];
    }
    arr[0] = sum;
    count = 1;
  }
  arr[count] = val;
  ++count;
}
```

* 假设数组的长度为 n，根据数据插入的位置的不同，可以分为 n 种情况，每种情况对应的复杂度是 `O(1)`.
* 除此之外，数组没有空闲空间插入数据的场景，这个时候时间复杂度是 `O(n)`.
* 这 n + 1 种情况发生的概率是一样的，都是 `1/(n + 1)`, 根据加权平均的计算方法，可以这么算：

![[均摊-加权平均算法.png]]
* 去掉系数之后，答案就是 `O(1)`.
* 观察这个案例和上面 `find` 案例的不同可以发现：
	* `find()` 函数在极端情况下，复杂度才为 `O(1)`。但 `insert()` 在大部分情况下，时间复杂度都为 `O(1)`。只有个别情况下，复杂度才比较高，为 `O(n)`。这是 `insert()` 第一个区别于 `find()` 的地方。
	* 对于 `insert()` 函数来说，`O(1)` 时间复杂度的插入和 `O(n)` 时间复杂度的插入，出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个 `O(n)` 插入之后，紧跟着 n - 1 个 `O(1)` 的插入操作，循环往复。
* 针对这种特殊场景，就可以使用摊还分析法，**摊还分析法得到时间复杂度称之为均摊时间复杂度。**
	* 每一次 `O(n)` 的插入操作，都会跟着 `n - 1` 次 `O(1)` 的插入操作，所以把耗时多的那次操作均摊到接下来的 `n - 1` 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 `O(1)`。

### 均摊时间复杂度的应用场景

* **对一个数据结构进行一组连续操作，大部分情况下的时间复杂度都很低，只有个别情况下时间复杂度比较高，且这些操作存在前后连贯的时序关系，这时就可以使用均摊时间复杂度来分析。**
* **在能够应用均摊时间复杂度分析的场景中，一般均摊时间复杂度就等于最好情况时间复杂度。**
* *在本课程的作者眼里，均摊时间复杂度就是一种特殊的平均情况时间复杂度。* 这点待考证。
	* 暂且尝试这样理解：💭
		* 平均情况时间复杂度：考虑所有情况；
		* 均摊时间复杂度：考虑单个周期。

## 扩展

* 请分析下面的 `add` 函数的时间复杂度。

```java
// 全局变量，大小为10的数组array，长度len，下标i。
int array[] = new int[10]; 
int len = 10;
int i = 0;

// 往数组中添加一个元素
void add(int element) {
 if (i >= len) { // 数组空间不够了
	 // 重新申请一个2倍大小的数组空间
	 int new_array[] = new int[len*2];
	 // 把原来array数组中的数据依次copy到new_array
	 for (int j = 0; j < len; ++j) {
		 new_array[j] = array[j];
	 }
	 // new_array复制给array，array现在大小就是2倍len了
	 array = new_array;
	 len = 2 * len;
 }
 // 将element放到下标为i的位置，下标i加一
 array[i] = element;
 ++i;
}
```

* 最好时间复杂度是 `O(1)`, 最坏时间复杂度是 `O(n)`, 均摊时间复杂度是 `O(1)`.
* 计算加权时间复杂度：
	* `1 * (1 / n + 1) + 1 * (1 / n + 1) + ... + 1 * (1 / n + 1) + n * (n + 1) = 1`
	* 得到计算结果 `O(1)`.
* 计算均摊时间复杂度：
	* 前 n 个操作的时间复杂度都是 `O(1)`, 第 n + 1 次操作的时间复杂度是 `O(n)`, 把最后一次操作均摊到前面 n 次，结论就是 `O(1)` 的时间复杂度。

#ALG 