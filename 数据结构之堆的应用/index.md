# 堆的应用

## 简言

* 搜索引擎的热门搜索榜单功能，其实就使用到了堆这种数据结构。

> 假设有一个包含 10 亿个搜索关键词的日志文件，如何快速获取到 Top 10 的搜索关键词呢？
> 学习曲线：★★★

## 堆的应用：优先级队列

* 优先级队列本质上也是队列，它遵循先进先出的原则。只是优先级队列先进先出的规则稍微有些不一样。
* **优先级队列中，数据的出队顺序遵循优先级而不是队首元素，优先级高的最先出队。**

### 优先级队列和堆

* 在各种数据结构中，使用堆来实现优先级队列是最高效，最直接的。因为这两者非常相似，一个堆就可以看作是优先级队列。某种程度上，它们只是概念的区分而已。
	* **往优先级队列中插入一个元素，相当于往堆中插入一个元素；**
	* **从优先级队列中取出优先级最高的元素，相当于取出堆顶元素。**
* 优先级队列有着非常广泛的使用场景，包括赫夫曼编码，图的最短路径，最小生成树算法等等。而且在很多语言中，直接提供了优先级队列的实现，例如 Java 中的 `PriorityQueue` 和 C++ 的 `priority_queue` 等。
* 下面是优先级队列的两个更加具体的应用场景，可以帮助我们理解堆。
	
### 1. 合并有序小文件

#### 设定场景

* 假设有 100 个小文件，每个文件大小 100 MB，其中存储了**有序**的字符串。我们希望把这些 100 个小文件合并成一个大文件。这里就可以使用优先级队列。

#### 一种解决方案

* 可以使用类似归并排序的思路。从 100 个文件里取第一个字符串，放入数组中，比较大小，再把最小的字符串取出放入合并后的大文件，并从数组中删除。
* 例如，最小的字符串来自 2b.txt 文件，我们就继续从 2b 文件里取下一个字符串，放到数组中，重新比较大小，并取出最小的字符串放入合并后的大文件，在数组里删除这个字符串。依次执行这些操作，直到所有文件的字符串都保存到大文件中。
* 这种方案可以解决问题，但是也会非常耗费时间和性能。因为每次更新字符串，就要重新遍历一遍数组的所有数据，执行起来不够高效。

#### 更好的解决方案

* 使用堆或者说优先级队列可以更好的实现这种场景。
* 我们不用数组，而是用小顶堆来存储所有小文件里取出来的字符串。这样堆顶的元素也就是优先级最高的数据，也就是最小的字符串，把它存入到大文件。每次数据更新，就把小文件的下一个字符串放入到堆中，重新堆化，得到新的堆顶元素，取出这个堆顶数据放入大文件，循环依次执行直到所有文件都放入大文件。
* 而删除堆顶元素和往堆中插入数据的时间复杂度都是 `O(logn)`, n 是堆中的数据个数，对应到这里就是 `log100`，显然会比前一种方式高效很多。

### 2. 高性能定时器

![[堆的应用之定时器示意图.png]]

#### 定时器设定背景

* 设置常规的定时器，可以每隔 1 秒就扫描一遍任务列表，但这种做法比较低效，主要原因在于：
	* 任务的约定执行时间有可能距离当前时间还有很久，这样就导致前面的扫描没有意义，只会耗费时间和性能。
	* 而且每次扫描都会扫描整个任务列表，如果任务列表很大就会非常耗时。

#### 解决方案

* 可以使用优先级队列来解决这类问题。
* 按照任务设定的时间，把任务存储在优先级队列中，队列首部（小顶堆的堆顶， 按间隔时间依次向后）存储的是最先执行的任务。
* 取得队首任务的执行时间点，和当前时间点相减，得到时间间隔 T。
	* *也就是从当前时间开始，T 秒过后定时器再执行任务。从现在到 T - 1 秒的这段实际案例，定时器无需做任何事情。*
* 当 T 秒过去，定时器取得队首的任务并执行之后，再重新计算新的队首任务的执行时间点和当前时间点的差值，把这个值作为定时器执行下一个任务需要等待的时间。
* 通过这样的方式，定时器不再需要间隔 1 秒就轮询一次，也不用遍历整个任务列表，性能也会相对提升。

### 优先级队列的实现

* 优先级队列的实现比堆的实现稍复杂一些，自己还没有手动实现。可以先参照[此处 `FastPriorityQueue`](https://github.com/lemire/FastPriorityQueue.js/blob/master/FastPriorityQueue.js)了解。

## 堆的应用：利用堆求 Top K

* 堆的另一个应用是求出前 k 大的数。
* 数组中按顺序取前 k 个数，构造成小顶堆；再遍历数组中剩下的元素，将其和堆顶元素比较，如果比堆顶元素大，就直接删除堆顶元素，用当前元素替代。重复此过程一直到遍历结束。这时堆中的元素就是前 k 大的数据。
* 遍历元素的时间复杂度是 `O(n)`. 堆化操作的时间复杂度是 `O(logk)`. 最坏情况下，所有的 n 个数据都需要堆化一次，这样的时间复杂度就是 `O(nlogk)`.

### 静态数据和动态数据的处理

* 针对静态数据，排序后取前 k 大的数据的时间复杂度是 `O(nlogk)`.
* 针对动态数据，求得的 Top K 数据就是实时的 Top K。
	* 这类动态数据集合中有两种操作，**一种是添加数据，另一个是查询当前的前 k 大数据。**
	* 如果每次插入或删除数据之后再排序，时间复杂度就会比较高；而使用堆化的方式实现，在始终维护一个 k 大小的小顶堆之后，任意数据的变动都只需要将其和堆顶元素比较。
	* 每次数据更新（*添加数据到集合中*），只需要把新数据和目前的堆顶元素比较，比堆顶元素大就替换堆顶元素，如果比它就小不作处理；后面再进行堆化即可。也就是后续数据的变化也只是堆化的时间复杂度。
	* 通过这样的方式，建堆时的时间复杂度是 `O(nlogk)`, 后续维护的时间复杂度就只有 `O(logk)`, 也就是堆化的时间复杂度。
	* 最终获取 Top K 的数据就是直接取出堆的数据。时间复杂度是 `O(1)`.

### 相关算法题 LeetCode

#### 求第 k 大的元素实现

* [LeetCode-215](https://leetcode-cn.com/problems/kth-largest-element-in-an-array/)：求第 k 大的元素
	* 可以用快排来排序后取得第 k 大元素；
	* *也可以使用堆排序直接取 k 个数建堆并堆化，之后对每个数据比较大小，直接得到结果而不用对所有的每个数字都排序。*
	* 下面是具体实现，堆的构造从索引 0 开始。

```typescript
/**
 * @description: 堆排序的方式
 * 时间复杂度 O(nlogk)
 * @param {number[]} nums
 * @param {number} k
 * @return {numer}
 */
function findKthLargest(nums: number[], k: number): number {
  /**
   * @description: 数组原地交换
   * @param {number[]} nums
   * @param {number} i
   * @param {number} j
   * @return {void}
   */
  function swap(nums: number[], i: number, j: number): void {
    [nums[j], nums[i]] = [nums[i], nums[j]];
  }
  /**
   * @description: 建堆，从后向前
   * @param {number[]} nums
   * @param {number} heapSize
   * @param {number} i
   * @return {void}
   */
  function buildHeap(nums: number[], heapSize: number) {
    // 因为从 0 开始，所以要减去 1
    for (let i = Math.floor(heapSize / 2 - 1); i >= 0; i--) {
      heapify(nums, heapSize, i);
    }
  }
  /**
   * @description: 自上而下堆化
   * @param {number[]} nums
   * @param {number} heapSize
   * @param {number} i
   * @return {void}
   */
  function heapify(nums: number[], heapSize: number, i: number) {
    let maxIndex = i;
    while (true) {
      if ((2 * i + 1) <= heapSize && nums[2 * i + 1] > nums[maxIndex]) maxIndex = 2 * i + 1;
      if ((2 * i + 2) <= heapSize && nums[(2 * i + 2)] > nums[maxIndex]) maxIndex = 2 * i + 2;
      if (maxIndex === i) break;
      swap(nums, i, maxIndex);
      i = maxIndex;
    }
  }

  // 建堆
  buildHeap(nums, nums.length);
  let len = nums.length - 1;
  // !取前 k 大的数，也就是判断到 k 为止
  for (let index = len; index > nums.length - k; index--) {
    swap(nums, len, 0);
    len--;
    // 从头开始堆化
    heapify(nums, len, 0);
  }

  return nums[0];
}
```

#### 数据流中的第 K 大元素

* [LeetCode-703](https://leetcode.cn/problems/kth-largest-element-in-a-stream/): 数据流中的第 K 大元素，详见题解。

## 堆的应用：利用堆求中位数

* 中位数：处在中间位置的数。
	* **如果数据的个数是奇数，数据从小到大排列后，`Math.floor(n / 2) + 1` 个数据就是中位数。（数据从 0 编号）**
	* **如果数据的个数是偶数，那么中间位置会有两个数据。这时取 `Math.floor(n / 2) + 1` 或 `Math.floor(n / 2)` 都可以。**

![[堆的应用之中位数示意图.png]]

* 对于一组静态数据，中位数始终是固定的，只需要排序后返回固定位置的值即可。尽管排序的成本可能会很大，但是编辑成本会比较小。

### 动态数据取中位数

* 但对于动态数据集合，中位数是不停变化的。这时如果每次都进行排序，则会比较耗费时间和性能了。
* 借助堆这种数据结构，不用排序也可以实现求中位数操作。
	* **我们维护两个堆，一个大顶堆和一个小顶堆。大顶堆存储前半部分数据，小顶堆存储后半部分数据，且小顶堆中的数据都大于大顶堆的数据。**
* 假设有 n 个数据，
	* n 是偶数，从小到大排序后，前 n / 2 的数据都在大顶堆中，后 n / 2 的数据都在小顶堆中。这样大顶堆的堆顶元素就是我们所要查询的中位数。
	* 如果 n 是奇数，则大顶堆存储 `Math.floor(n / 2) + 1` 的数据，小顶堆存储 `Math.floor(n / 2)` 的数据。中位数仍然是大顶堆的堆顶元素。

![[堆的应用之动态数据中位数示意图.png]]

* 但我们前面也提到数据是动态变化的。**新增数据的时候，判断数据是否小于大顶堆的堆顶元素，是的话就加入大顶堆，否的话就加入小顶堆。**
	* 在加入数据之后，两个堆的数据量很可能是不一样的。这时**通过不断移动堆顶元素到另一个堆来平衡两者的数据量，最终使得堆满足上述数量大小关系。**
	* 具体如下图所示：

![[堆的应用之动态数据调整中位数示意图.png]]

* **通过维护一个大顶堆和一个小顶堆的方式，我们实现了在动态数据集合中求中位数的操作。** 每当有数据插入时，涉及到堆化操作，时间复杂度是 `O(logn)`, 但是求中位数时，只需要返回大顶堆的堆顶元素即可，时间复杂度就是 `O(1)`.

### 通过两个堆求得 99%

* 通过两个堆不仅可以求得中位数，也可以快速求得其他百分位的数据。原理是类似的。
* 下面来分析如何快速求出接口的 99% 响应时间。

#### 99% 响应时间

* 中位数的概念就是将数据从小到大排列，处于中间位置的就叫中位数，这个数据会大于等于前面 50% 的数据。**99 百分位数的概念类比到中位数，就是数据从小到大排列后，99 百分位数会大于前面 99% 数据。**
* 下面的图可以帮助理解。

![[堆的应用之99百分位数.png]]

* 99% 响应时间，就是如果有 100 个接口访问请求，每个接口请求的响应时间都不同，比如 51 毫秒，103 毫秒，23 毫秒等，把这 100 个接口的请求响应时间依次排列，排在第 99 位的数据就是 99%响应时间，也叫 99 百分位响应时间。
* 现在我们仍然可以建立并维护两个堆，大顶堆存储 n 个数据中 `n * 99%` 的数据，小顶堆中存储 `n * 1%` 的数据。**大顶堆的堆顶元素就是所谓的 99% 响应时间。**
* 新增数据的判断逻辑与前文相同。除此之外，插入数据后需要重新计算两个堆的数据量个数是否依然满足 99:1 的比例关系。如果不满足，就继续移动堆顶元素，直到满足为止。
* 求 99% 响应时间的时间复杂度和求中位数的基本一致，插入数据涉及堆化，它的时间复杂度是 `O(logn)`. 获取 99% 响应时间的时候，时间复杂度是 `O(1)`.

## 工业级应用：获取热门搜索关键词

### 设定场景

* 首先，假定处理的场景是单机，而且可用内存只有 1 G。此时，有 10 亿条搜索关键词的数据的日志文件需要检索。

### 一种解决方案

* 搜索的关键词日志中，会有很多重复的关键词，所以也需要统计关键词出现的频率。我们可以使用散列表、平衡二叉查找树或者其他支持快速查找和插入的数据结构来存储关键词和出现的次数。
* 假设使用散列表，顺序扫描 10 亿条数据；如果关键词在散列表中存在，就把次数加一，否则插入数据到散列表，并记录次数为 1. 遍历结束后，散列表就存储了不重复的搜索关键词和出现的次数。
* 再根据上文的求 Top K 的方案，只需要维护一个大小为 10 的小顶堆，遍历散列表，取出每个关键词和所对应的出现次数，与堆顶元素对比，如果比堆顶元素存储的次数大，就删除堆顶元素，把这个关键词插入后堆化，形成新的小顶堆，反之则不作处理。

#### 该方案的漏洞和缺陷

* 这种方案的问题也比较显而易见。10 亿条的数据，假设不重复的有 1 亿条，每条数据的关键词 50 个字节，那么 1 亿个关键词也会占用 5G 的空间大小，超过了我们最初的设定。而且散列表为了避免冲突，需要设置较大的装载因子，也会占用比较多的空间。最终导致这种方案无法让所有搜索关键词一次性加入到内存中。

### 更好的解决方案

* **利用相同的值通过哈希算法生成的哈希值也相同这一特性**，我们使用哈希算法遍历数据求得哈希值，再把哈希值对 10 取模后，把所有的 10 亿条数据分片到 10 个文件中。
* 每个文件都只有约 1 亿条数据，去掉重复的可能只剩下 1000 万个，平均关键词大小约为 50 字节，总的大小就是 500M，内存可以容纳。
* 针对这 10 个文件，每个文件我们都维护各自的散列表和堆，分别求出 Top 10，把这 10 个 Top 10 放在一起，取出出现次数最多的 10 个关键词就是搜索关键词 Top 10.

## 小结

* 这一章节主要围绕堆在生产环境中的应用，应用包括优先级队列，求 Top K 问题和求中位数问题。
* 优先级队列根据优先级的顺序出队。
	* 优先级队列其实就是堆的另一种称谓。
* 求 Top K 问题可以分解为针对静态数据和针对动态数据，只需要一个堆，就可以非常高效地解决查询 Top K 数据的问题。
* 求中位数实际上有很多变形，比如求 99 百分位数据，90 百分位数据等，但是它们的处理思路都是一样的，使用两个堆，一个大顶堆和一个小顶堆，随着数据的动态添加，动态调整两个堆中的数据，最后大顶堆的堆顶元素就是要求的数据。

## 扩展

* 一个访问量极大的新闻网站，希望把点击量排名前 10 的新闻摘要滚动显示在首页 banner 上，并且每隔 1 小时更新一次，请问可以如何实现？

#ALG #ADT 